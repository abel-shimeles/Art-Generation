{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f2c9bb",
   "metadata": {},
   "source": [
    "# Neural Style Transfer\n",
    "\n",
    "This notebook is inspired by an algorithm created by [Gatys et al. (2015).](https://arxiv.org/abs/1508.06576) called Neural Style Transfer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c093460",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47822f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6592d",
   "metadata": {},
   "source": [
    "Neural Style Transfer (NST) is one of the most fun and interesting optimization techniques in deep learning. It merges two images, namely: a <strong>\"content\" image (C)</strong> and a <strong>\"style\" image (S)</strong>, to create a <strong>\"generated\" image (G)</strong>. The generated image G combines the \"content\" of the image C with the \"style\" of image S.\n",
    "\n",
    "We are going to combine the Louvre museum in Paris (content image C) with the impressionist style of Claude Monet (style image S) to generate the following image:\n",
    "\n",
    "<img src=\"images/louvre_generated.png\" style=\"width:750px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd934e02",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Neural Style Transfer (NST) uses a previously trained convolutional network, and builds on top of that. \n",
    "\n",
    "We will be using the eponymously named VGG network from the [original NST paper](https://arxiv.org/abs/1508.06576) published by the Visual Geometry Group at University of Oxford in 2014. Specifically, we'll use VGG-19, a 19-layer version of the VGG network. This model has already been trained on the very large ImageNet database, and has learned to recognize a variety of low level features (at the shallower layers) and high level features (at the deeper layers). \n",
    "\n",
    "We will run the following code to load parameters from the VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889746d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "img_size = 400\n",
    "vgg = tf.keras.applications.VGG19(include_top=False,\n",
    "                                  input_shape=(img_size, img_size, 3),\n",
    "                                  weights='pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "vgg.trainable = False\n",
    "pp.pprint(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39133c2e",
   "metadata": {},
   "source": [
    "## Neural Style Transfer (NST)\n",
    "\n",
    "Next, we will be building the Neural Style Transfer (NST) algorithm in three steps:\n",
    "- First, we will build the content cost function\n",
    "- Second, we will build the style cost function\n",
    "- Finally, we will build total cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1055b2a",
   "metadata": {},
   "source": [
    "### Content Cost\n",
    "\n",
    "In the following cells, we will compute the Content Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = Image.open(\"images/louvre.jpg\")\n",
    "print(\"The content image (C) shows the Louvre museum's pyramid surrounded by old Paris buildings, against a sunny sky with a few clouds.\")\n",
    "content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(content_output, generated_output):\n",
    "    a_C = content_output[-1]\n",
    "    a_G = generated_output[-1]\n",
    "    \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_C_unrolled = tf.reshape(a_C, shape=[m, n_H * n_W, n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G, shape=[m, n_H * n_W, n_C])\n",
    "    \n",
    "    J_content =  tf.reduce_sum(tf.square(a_C_unrolled - a_G_unrolled))/(4.0 * n_H * n_W * n_C)\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb52ffea",
   "metadata": {},
   "source": [
    "The Style image we are going to use is the following, which was painted in the style of <b>[impressionism](https://en.wikipedia.org/wiki/Impressionism)</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a2c83",
   "metadata": {},
   "source": [
    "### Style Cost\n",
    "\n",
    "In the following cells, we will compiute the style cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Image.open(\"images/monet_800600.jpg\")\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    GA = tf.matmul(A, tf.transpose(A))\n",
    "\n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17585f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_S = tf.transpose(tf.reshape(a_S, shape=[-1, n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G, shape=[-1, n_C]))\n",
    "    \n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "    \n",
    "    J_style_layer = tf.reduce_sum(tf.square(GS - GG))/(4.0 *(( n_H * n_W * n_C)**2))\n",
    "        \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266197e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.get_layer('block5_conv4').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),\n",
    "    ('block2_conv1', 0.2),\n",
    "    ('block3_conv1', 0.2),\n",
    "    ('block4_conv1', 0.2),\n",
    "    ('block5_conv1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n",
    "    J_style = 0\n",
    "    \n",
    "    a_S = style_image_output[:-1]\n",
    "    a_G = generated_image_output[:-1]\n",
    "    \n",
    "    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n",
    "        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n",
    "        J_style += weight[1] * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    J = alpha * J_content + beta * J_style\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc3fe7",
   "metadata": {},
   "source": [
    "### Load the Content Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = np.array(Image.open(\"images/louvre_small.jpg\").resize((img_size, img_size)))\n",
    "content_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n",
    "\n",
    "print(content_image.shape)\n",
    "plt.imshow(content_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162768e",
   "metadata": {},
   "source": [
    "### Load the Style Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b329899",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image =  np.array(Image.open(\"images/monet.jpg\").resize((img_size, img_size)))\n",
    "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
    "\n",
    "print(style_image.shape)\n",
    "plt.imshow(style_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09881c2",
   "metadata": {},
   "source": [
    "### Randomly Initialize the Image to be Generated\n",
    "Now, we get to initialize the \"generated\" image as a noisy image created from the content_image.\n",
    "\n",
    "* The generated image is slightly correlated with the content image.\n",
    "* By initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the \"generated\" image more rapidly match the content of the \"content\" image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c725e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "noise = tf.random.uniform(tf.shape(generated_image), -0.25, 0.25)\n",
    "generated_image = tf.add(generated_image, noise)\n",
    "generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "print(generated_image.shape)\n",
    "plt.imshow(generated_image.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3c7b9",
   "metadata": {},
   "source": [
    "### Load the Pre-trained VGG19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_outputs(vgg, layer_names):\n",
    "    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = [('block5_conv4', 1)]\n",
    "\n",
    "vgg_model_outputs = get_layer_outputs(vgg, STYLE_LAYERS + content_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_target = vgg_model_outputs(content_image)\n",
    "style_targets = vgg_model_outputs(style_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71e7cd",
   "metadata": {},
   "source": [
    "### Total Cost\n",
    "In the following cells, we will compute the total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dee0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "a_C = vgg_model_outputs(preprocessed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ee21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
    "a_S = vgg_model_outputs(preprocessed_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor * 255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor) > 3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "@tf.function()\n",
    "\n",
    "def train_step(generated_image, alpha = 10, beta = 40):\n",
    "    with tf.GradientTape() as tape:\n",
    "        a_G = vgg_model_outputs(generated_image)\n",
    "        \n",
    "        J_style = compute_style_cost(a_S, a_G)\n",
    "        J_content = compute_content_cost(a_C, a_G)\n",
    "        J = total_cost(J_content, J_style,alpha = alpha, beta = beta)\n",
    "        \n",
    "    grad = tape.gradient(J, generated_image)\n",
    "\n",
    "    optimizer.apply_gradients([(grad, generated_image)])\n",
    "    generated_image.assign(clip_0_1(generated_image))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a840bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1110a8",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "for i in range(epochs):\n",
    "    train_step(generated_image)\n",
    "    if i % 250 == 0:\n",
    "        print(f\"Epoch {i} \")\n",
    "    if i % 250 == 0:\n",
    "        image = tensor_to_image(generated_image)\n",
    "        plt.imshow(image)\n",
    "        image.save(f\"output/image_{i}.jpg\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(content_image[0])\n",
    "ax.title.set_text('Content image')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(style_image[0])\n",
    "ax.title.set_text('Style image')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(generated_image[0])\n",
    "ax.title.set_text('Generated image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8578971",
   "metadata": {},
   "source": [
    "You can find the generated images in the output/ directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
